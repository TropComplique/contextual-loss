{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from other_losses import PerceptualLoss, StyleLoss, TotalVariationLoss\n",
    "from extractor import Extractor\n",
    "from utils import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENT = Image.open('dog.jpg')\n",
    "STYLE = Image.open('The_Starry_Night.jpg').resize(CONTENT.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try the classical neural style algorithm (by Gatys et al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of features to use\n",
    "CONTENT_LAYERS = ['conv4_2']\n",
    "STYLE_LAYERS = ['conv3_1', 'conv4_1', 'conv5_1']\n",
    "\n",
    "\n",
    "class Loss(nn.Module):\n",
    "\n",
    "    def __init__(self, content, style, initial=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            content: an instance of PIL image.\n",
    "            style: an instance of PIL image.\n",
    "            initial: an instance of PIL image or None.\n",
    "        \"\"\"\n",
    "        super(Loss, self).__init__()\n",
    "\n",
    "        # image to start optimization from\n",
    "        if initial is None:\n",
    "            mean, std = 0.5, 1e-3\n",
    "            w, h = content.size\n",
    "            initial = mean + std * torch.randn(1, 3, h, w)\n",
    "        else:\n",
    "            assert initial.size == content.size\n",
    "            initial = to_tensor(initial)\n",
    "\n",
    "        # images\n",
    "        content = to_tensor(content)\n",
    "        style = to_tensor(style)\n",
    "        self.x = nn.Parameter(data=initial, requires_grad=True)\n",
    "\n",
    "        # features\n",
    "        feature_names = CONTENT_LAYERS + STYLE_LAYERS\n",
    "        self.vgg = Extractor(feature_names)\n",
    "        cf = self.vgg(content)\n",
    "        sf = self.vgg(style)\n",
    "\n",
    "        # create losses\n",
    "        self.perceptual = nn.ModuleDict({n: PerceptualLoss(cf[n]) for n in CONTENT_LAYERS})\n",
    "        self.style = nn.ModuleDict({n: StyleLoss(sf[n]) for n in STYLE_LAYERS})\n",
    "        self.tv = TotalVariationLoss()\n",
    "\n",
    "    def forward(self):\n",
    "\n",
    "        f = self.vgg(self.x)\n",
    "        content_loss = torch.tensor(0.0, device=self.x.device)\n",
    "        style_loss = torch.tensor(0.0, device=self.x.device)\n",
    "\n",
    "        for n, m in self.perceptual.items():\n",
    "            content_loss += m(f[n])\n",
    "\n",
    "        for n, m in self.style.items():\n",
    "            style_loss += m(f[n])\n",
    "\n",
    "        tv_loss = self.tv(self.x)\n",
    "        return content_loss, style_loss, tv_loss\n",
    "\n",
    "    \n",
    "def to_tensor(x):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        x: an instance of PIL image.\n",
    "    Returns:\n",
    "        a float tensor with shape [3, h, w],\n",
    "        it represents a RGB image with\n",
    "        pixel values in [0, 1] range.\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    x = torch.FloatTensor(x)\n",
    "    return x.permute(2, 0, 1).unsqueeze(0).div(255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize with L-BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "objective = Loss(CONTENT, STYLE, initial=CONTENT).to(DEVICE)\n",
    "params = filter(lambda x: x.requires_grad, objective.parameters())\n",
    "\n",
    "optimizer = optim.LBFGS(\n",
    "    params=params, lr=0.5, max_iter=300, \n",
    "    tolerance_grad=-1, tolerance_change=-1\n",
    ")\n",
    "\n",
    "i = [0]\n",
    "text = 'i:{0},total:{1:.2f},content:{2:.3f},style:{3:.6f},tv:{4:.4f}'\n",
    "def closure():\n",
    "\n",
    "    objective.x.data.clamp_(0, 1)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    content_loss, style_loss, tv_loss = objective()\n",
    "    total_loss = content_loss + 500 * tv_loss + 100000 * style_loss\n",
    "    total_loss.backward()\n",
    "    \n",
    "    i[0] += 1\n",
    "    print(text.format(i[0], total_loss.item(), content_loss.item(), style_loss.item(), tv_loss.item()))\n",
    "    return total_loss\n",
    "\n",
    "optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = 255 * objective.x.clamp(0, 1).detach().permute(0, 2, 3, 1)[0].cpu().numpy()\n",
    "Image.fromarray(result.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = objective.x.detach().permute(0, 2, 3, 1)[0].cpu().numpy()\n",
    "result = 255*(result - result.min())/(result.max() - result.min())\n",
    "Image.fromarray(result.astype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "objective = Loss(CONTENT, STYLE, initial=CONTENT).to(DEVICE)\n",
    "params = filter(lambda x: x.requires_grad, objective.parameters())\n",
    "\n",
    "NUM_STEPS = 300\n",
    "optimizer = optim.Adam(params, lr=0.1)\n",
    "\n",
    "for i in range(NUM_STEPS):\n",
    "    \n",
    "    objective.x.data.clamp_(0, 1)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    content_loss, style_loss, tv_loss = objective()\n",
    "    total_loss = content_loss + 1000 * tv_loss + 100000 * style_loss\n",
    "    total_loss.backward()\n",
    "\n",
    "    print(text.format(i, total_loss.item(), content_loss.item(), style_loss.item(), tv_loss.item()))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = 255 * objective.x.clamp(0, 1).detach().permute(0, 2, 3, 1)[0].cpu().numpy()\n",
    "Image.fromarray(result.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = objective.x.detach().permute(0, 2, 3, 1)[0].cpu().numpy()\n",
    "result = 255*(result - result.min())/(result.max() - result.min())\n",
    "Image.fromarray(result.astype('uint8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
